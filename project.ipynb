{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyledennis/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from smote import smote_sampling\n",
    "from train_and_pred import train_and_predict\n",
    "from accuracy_metrics import calculate_metrics\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "^ No nulls\n",
      "There are 492 fraudulent transactions- about 0.1727 percent of the dataset.\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# check is for nulls\n",
    "print(data.isnull().values.any())\n",
    "print('^ No nulls')\n",
    "\n",
    "# obtain X and y\n",
    "X = data[[\"Time\", \"Amount\", \"V1\", \"V2\"]]\n",
    "y = data['Class']\n",
    "\n",
    "# find fraud proportion\n",
    "# fraudCount = len(data[data['Class'] == 1])\n",
    "fraud_count = (y == 1).sum()\n",
    "fraud_percentage = (fraud_count/len(X))*100 \n",
    "fraud_percentage_rounded = round(fraud_percentage, 4)\n",
    "\n",
    "# print fraud distribution\n",
    "print('There are ' + str(fraud_count) + ' fraudulent transactions- about ' + str(fraud_percentage_rounded) + ' percent of the dataset.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SMOTE sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68235 fraudulent transactions in the training data- about 23.0768 percent of the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training set(80%) and test set(20%) using stratified splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=7)\n",
    "\n",
    "# apply SMOTE to training data- have new minority class be about 30 percent of the majority class\n",
    "X_train_sampled, y_train_sampled = smote_sampling(X_train, y_train, 0.3)\n",
    "\n",
    "# find new fraud proportion\n",
    "fraud_count_new = (y_train_sampled == 1).sum()\n",
    "fraud_percentage_new = (fraud_count_new/len(X_train_sampled))*100 \n",
    "fraud_percentage_rounded_new = round(fraud_percentage_new, 4)\n",
    "\n",
    "# print new fraud distribution\n",
    "print('There are ' + str(fraud_count_new) + ' fraudulent transactions in the training data- about ' + str(fraud_percentage_rounded_new) + ' percent of the dataset.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9984375548611355, 'precision(y=1)': 0.8461538461538461, 'recall': 0.9984375548611355, 'f1-score': 0.9978399048095916}\n"
     ]
    }
   ],
   "source": [
    "# BASE MODEL\n",
    "# Scale time and amount features(PC's were already scaled)in training and test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy() \n",
    "X_train_scaled[['Time', 'Amount']] = scaler.fit_transform(X_train[['Time', 'Amount']])\n",
    "\n",
    "X_test_scaled = X_test.copy() \n",
    "X_test_scaled[['Time', 'Amount']] = scaler.fit_transform(X_test[['Time', 'Amount']])\n",
    "\n",
    "# Initialize model\n",
    "lr = LogisticRegression(random_state=22)\n",
    "\n",
    "# Fit model and get predictions\n",
    "y_pred_lr = train_and_predict(lr, X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "# Get accuracy metrics\n",
    "lr_metrics = calculate_metrics(y_test, y_pred_lr)\n",
    "print(lr_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Mar  1 2023, 12:33:47) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4db5150d9307c9db32b72c66369bb63432993cbb0a7e65d16b4aeb4fba66c21e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
